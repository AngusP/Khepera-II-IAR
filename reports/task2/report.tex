
%     %%%%%%%%%%%%%%%
%
%     P A C K A G E S
%
%     %%%%%%%%%%%%%%%

\documentclass[11pt, a4paper]{article}
\usepackage{fontspec}
\usepackage{caption}
\usepackage{mathtools}

% DOCUMENT LAYOUT
\usepackage{geometry}
\geometry{a4paper, textwidth=42em, textheight=70em, marginparsep=0.5em, marginparwidth=3.5em}
\setlength\parindent{0em}
\setlength\parskip{0.75em}
\captionsetup{width=0.8\textwidth}

% FONTS
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{xunicode}
\usepackage{xltxtra}
\defaultfontfeatures{Mapping=tex-text}
%\setromanfont [Ligatures={Common}, Numbers={OldStyle}, Variant=01]{Linux Libertine O}
%\setmonofont[Scale=0.8]{Monaco}
%%% modified by Karol Kozio≈Ç for ShareLaTeX use
\setmainfont[
  Ligatures={Common}, Numbers={OldStyle}, Variant=01,
  BoldFont=LinLibertine_RB.otf,
  ItalicFont=LinLibertine_RI.otf,
  BoldItalicFont=LinLibertine_RBI.otf
]{LinLibertine_R.otf}
\setmonofont[Scale=0.8]{DejaVuSansMono.ttf}

% HEADINGS
\usepackage{sectsty}
\usepackage[normalem]{ulem}
\sectionfont{\mdseries\upshape\Large}
\subsectionfont{\mdseries\scshape\normalsize}
\subsubsectionfont{\mdseries\upshape\large}

\renewenvironment{abstract}{%
{\mdseries\scshape\Large\abstractname}
\vspace{1em}\\
}{\par\noindent}

% LISTINGS
\usepackage{listings}
\usepackage{color}
\usepackage{appendix}

\usepackage{color}
\definecolor{codered}{rgb}{0.61,0.21,0.18}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{1.0,1.0,1.0}
\lstset{
  backgroundcolor=\color{backcolour},   
  commentstyle=\color{codegray},
  keywordstyle=\color{codered},
  numberstyle=\tiny\color{codegreen},
  stringstyle=\color{codepurple},
  basicstyle=\footnotesize\ttfamily,        % the size of the fonts that are used for the code
  breaklines=true,                          % sets automatic line breaking
  keepspaces=true,                          % keeps spaces in text, useful for keeping indentation of code
  showspaces=false,                         % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,                   % underline spaces within strings only
  showtabs=false,                           % show tabs within strings adding particular underscores
  stepnumber=2,                             % the step between two line-numbers. If it's 1, each line will be numbered
  tabsize=2, 	                            % sets default tabsize to 2 spaces
  title=\lstname                            % show the filename of files included with \lstinputlisting
}


%     %%%%%%%%%%%%%%%
%
%     D O C U M E N T
%
%     %%%%%%%%%%%%%%%


\begin{document}
\title{IAR Task 2 Report}
\author{Angus Pearson -- s1311631\\ Jevgenij Zubovskij -- s1346981}
\date{\today}
\maketitle

%       ^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^


\begin{abstract}
  We present an implementation of an algorithm similar to \textit{Bug2}\cite{bug_algorithm} 
  built atop reactive obstacle collision avoidance and edge following behaviour developed for 
  \textit{Task1}. The existing architecture is extended to include storing timestamped poses 
  in a Redis\cite{Redis} key/value \& pubsub server, goal state publishing and real-time visualisation 
  using a Redis to ROS\cite{ROS} pipe, odometry, sensory information and goals
  are displayed graphically in Rviz. After-the-fact plotting is provided with MatPlotLib independent
  of ROS.

  In our testing, the robot was able to navigate to within 10cm of the origin (it's start point) 
  from an abitary location in multiple environments successfully in ${12/15}$ experiments, where each 
  environment was designed to evoke edge-case behaviour considered hard for the algorithm. The 
  algorithm performs comparably in a static world and a dynamic one in which other actors 
  (e.g. Humans) present a transient obstacle. 
\end{abstract}

%       ^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^


\section{Introduction}

The second IAR assignment entails extending the existing systems from Task 1 with Odometry, 
to maintain an estimate of the robot's location, enabling rendering of it's movement both 
in real time and after completion. The task also calls for `Return to home' ability, either 
``by retracing its outward route or more directly''. As an extention, basic mapping (without
filtering to correct for odometry dead-reckoning drift) of the world is desireable. We utilise 
Rviz, a popular graphical tool for ROS to live-render the Khepera Robot's pose, odometry trail,
obstacles perceived by the IR range sensors and goal (a plan-line to the origin).


\section{Plotting}

TODO ...........

%       ^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^


\section{Odometry}


\subsection{Research}

Several methods of odometry were researched, implemented and tested. Firstly, have found several
ways of calculating the pose (X,Y,$\Theta$). The first one we found was the one we ended up using
and it will be described in detail in the next section. However, we did not wish to rely on such 
a simplistic approach alone due to odometry drifting with time due to wheel slippage, non-ideal encoders etc.

Hence, we tried researching on how to compose an error function for odometry, or possibly adapt an already
developed approach. We found waht seemed like a much better integrator for pose estimation as it was even 
recommended to be used by students. The algorithm was very similar to the one we eventually adapted, it 
used a fourth order Runge-Kutta numerical integrator\textit{}\cite{runge_kutta}. However, upon implementation, and
testing if it correctly detects the robot going in a straight line (equal motor speeds) and said algorithm
absolutely fialing, it was abandoned. 

Hence, we decided to use the simplistic algorithm but find an error function for it. However, upon inquiring
Dr. Webb about if that should be done and receivign an answer it should not, the way to do odometry was decided.

lastly, it should be noted that all the odometry methods use encoder values to estimate pose and we assume
that the data given in the Khepera 2 User Manual\textit{}\cite{khepera_manual} redgarding each milimiter distance being 
equivalent to $12$ encoder ticks.


\subsection{Method Chosen}

The method chosen for calculating pose\textit{}\cite{odo_used} use simple trigonometry and differential drive on 
the wheels to perform its task. Please see the relevant document for deriviation of the formulas. The position for 
(X,Y,$\Theta$) are in in relation to initial position, where the forward-facing direction is the positive half of the
X-axis and initial X,Y are ($0$,$0$) and therefore further angles are in that frame of reference.

\begin{enumerate}

	\item Distance driven by each wheel $\Delta s_{wheel} = \frac {\Delta ticks_{wheel} } {12 ^{ticks}/_{mm}} $
	\item Total distance driven $ \Delta s = \frac{\Delta s_{r} + \Delta s_{l} }{2}$
	\item Direction in which it was driven (and new orientation) $\Theta s = \frac{ \Delta s_{r} - \Delta s_{l} }{2L}$
	\item X position update $X_{n+1} = X_{n} + \Delta s \cos (\Theta)$
	\item Y position update $Y_{n+1} = Y_{n} + \Delta s \sin (\Theta)$


\end{enumerate}


The distance driven by each wheel is not as per document we mainly used as we know how many (encoder) ticks are per milimeter.
The method proved very sucessful as will be shown in subsequent sections. The encoders are incremental and are able to detect both
forward and backward movement of the wheel, hence, the above method works without any tricks.

\subsection{Method Chosen}


%       ^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^

\section{Return Algorithm}


%       ^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^



\section{Testing Plotting}


%       ^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^


\section{Testing Odometry}


%       ^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^



\section{Testing Return Algorithm}



%       ^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^

\newpage
\section{Results}


\section{Discussion \& Possible Improvements}


%       ^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^


\begin{thebibliography}{2}

\bibitem{principlesrobot}
\par{Principles of Robot Motion: Theory, Algorithms, and Implementation}\\
\textit{Howie Choset}

\bibitem{Redis}
\par{Redis is an open source (BSD licensed), in-memory data structure store, used as database, cache and message broker. It supports data structures such as strings, hashes, lists, sets, sorted sets with range queries, bitmaps, hyperloglogs and geospatial indexes with radius queries.}\\
\textit{http://redis.io}

\bibitem{ROS}
\par{The Robot Operating System (ROS) is a flexible framework for writing robot software. It is a collection of tools, libraries, and conventions that aim to simplify the task of creating complex and robust robot behavior across a wide variety of robotic platforms.}\\
\textit{http://www.ros.org/}

\bibitem{runge_kutta} 
\par{Fourth order Runge - Kutta algorithm for pose estimation} \\
\textit{https://www.cs.cmu.edu/afs/cs.cmu.edu/academic/class/16311/www/s07/labs/NXTLabs/Lab\%203.html }

\bibitem{error_function} 
\par{University of Tennessee lecture on Localization and Mapping, includes odometry estimation and error function} \\
\textit{http://web.eecs.utk.edu/\~leparker/Courses/CS594-fall08/Lectures/Nov-13-Localization-Mapping-I.pdf}

\bibitem{odo_used} 
\par{Princeton University lecture on Autonomous Robot Navigation with odometry formulas and their deriviation from geometry and trigonometry} \\
\textit{https://www.cs.princeton.edu/courses/archive/fall11/cos495/COS495-Lecture5-Odometry.pdf }

\bibitem{khepera_paper} 
\par{A paper on Experimental Odometry Calibration of the Mobile Robot Khepera II Based on the Least-Squares Technique from which we took inspiration on calibration and confirmation we are doing odometry in the right fashion} \\
\textit{http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1570321}


\bibitem{khepera_manual} 
\par{Khepera 2 user Manual containing all the fundamental information about the Khepera 2 robot, including information abotu encoders and their value meanings} \\
\textit{http://ftp.k-team.com/khepera/documentation/Kh2UserManual.pdf}

\bibitem{bug_algorithm} 
\par{Carnegie Mellon University Robotic Motion Planning: Bug Algorithms paper / lecture that explores Bug algorithms, including their waknesses, strengths and comparing them with one another. Hence, incrementally building a robust navigation algorithm that does not need any mapping and uses only direction to goal (global position of robot and goal), odometry and a pinch of reactive control} \\
\textit{https://www.cs.cmu.edu/~motionplanning/lecture/Chap2-Bug-Alg\_howie.pdf}




\end{thebibliography}


\begin{appendices}
\section*{Appendix}
\subsection{Code Listings}
\lstinputlisting[language=python]{../../main.py}
\lstinputlisting[language=python]{../../data.py}
\lstinputlisting[language=python]{../../state.py}
\lstinputlisting[language=python]{../../bug_state.py}
\lstinputlisting[language=python]{../../bug_algorithm.py}
\lstinputlisting[language=python]{../../navigation_algorithm.py}
\lstinputlisting[language=python]{../../odometry_algorithm.py}
\lstinputlisting[language=python]{../../odometry_state.py}
\lstinputlisting[language=python]{../../constants.py}
\end{appendices}


\end{document}
