
%     %%%%%%%%%%%%%%%
%
%     P A C K A G E S
%
%     %%%%%%%%%%%%%%%

\documentclass[11pt, a4paper]{article}
\usepackage{fontspec}
\usepackage{caption}
\usepackage{mathtools}
\usepackage{gensymb}
\usepackage{float}
\usepackage{algorithmic}

% DOCUMENT LAYOUT
\usepackage{geometry}
\geometry{a4paper, textwidth=42em, textheight=70em, marginparsep=0.5em, marginparwidth=3.5em}
\setlength\parindent{0em}
\setlength\parskip{0.75em}
\captionsetup{width=0.8\textwidth}

% FONTS
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{xunicode}
\usepackage{xltxtra}
\defaultfontfeatures{Mapping=tex-text}
%\setromanfont [Ligatures={Common}, Numbers={OldStyle}, Variant=01]{Linux Libertine O}
%\setmonofont[Scale=0.8]{Monaco}
%%% modified by Karol Kozio≈Ç for ShareLaTeX use
\setmainfont[
  Ligatures={Common}, Numbers={OldStyle}, Variant=01,
  BoldFont=LinLibertine_RB.otf,
  ItalicFont=LinLibertine_RI.otf,
  BoldItalicFont=LinLibertine_RBI.otf
]{LinLibertine_R.otf}
\setmonofont[Scale=0.8]{DejaVuSansMono.ttf}

% HEADINGS
\usepackage{sectsty}
\usepackage[normalem]{ulem}
\sectionfont{\mdseries\upshape\Large}
\subsectionfont{\mdseries\scshape\normalsize}
\subsubsectionfont{\mdseries\upshape\normalsize}

\renewenvironment{abstract}{%
{\mdseries\scshape\Large\abstractname}
\vspace{1em}\\
}{\par\noindent}


\usepackage[superscript]{cite}

% LISTINGS
\usepackage{listings}
\usepackage{color}
\usepackage{appendix}

\usepackage{color}
\definecolor{codered}{rgb}{0.61,0.21,0.18}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{1.0,1.0,1.0}
\lstset{
  backgroundcolor=\color{backcolour},   
  commentstyle=\color{codegray},
  keywordstyle=\color{codered},
  numberstyle=\tiny\color{codegreen},
  stringstyle=\color{codepurple},
  basicstyle=\footnotesize\ttfamily,        % the size of the fonts that are used for the code
  breaklines=true,                          % sets automatic line breaking
  keepspaces=true,                          % keeps spaces in text, useful for keeping indentation of code
  showspaces=false,                         % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,                   % underline spaces within strings only
  showtabs=false,                           % show tabs within strings adding particular underscores
  stepnumber=2,                             % the step between two line-numbers. If it's 1, each line will be numbered
  tabsize=4, 	                            % sets default tabsize to 2 spaces
  title=\lstname                            % show the filename of files included with \lstinputlisting
}



%     %%%%%%%%%%%%%%%
%
%     D O C U M E N T
%
%     %%%%%%%%%%%%%%%


\begin{document}
\title{IAR Task 3 Final Report}
\author{Angus Pearson -- s1311631\\ Jevgenij Zubovskij -- s1346981}
\date{\today}
\maketitle

%       ^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^


\begin{abstract}
Given a \textit{Khepera II} robot with no prior knowledge of it's environment, and under the 
assumption that it's world is deterministic (TODO: There's a better word for that), we are able 
to develop the agency required by the task of exploring, discovering food and returning it to the 
robot's nest. This is built atop an \textit{A*} planning system, stochastic \textit{Adaptive Monte Carlo 
Localisation}\cite{principlesrobot} to correct compound localisation error, and a dyanmical 
\textit{Occupancy Grid} generation architecture, the combination of which constitute a SLAM system.

Our existing Architecture from IAR Assignments 1\cite{task1_report} \& 2\cite{task2_report} is further
extended, building upon the \textit{Bug2} behaviour, Redis datastore and ROS/Rviz real-time 
visualisation.

\end{abstract}


%       ^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^


\section{Dynamical Occupancy Grid}

We build up a map (occupancy grid) of the environment as the robot explores. At time 0, the map
is empty. In this implementation, the dimensions of the grid are effectively infinite, as there are
mechanisms allowing for automatic expansion in the even of the robot leaving the soft boundaries of
the grid. The grid is stored as a hashmap in Redis, not a 2D array, with missing keys being assumed 
unoccupied.

As a grid resize effectively invalidates any 2D cached array version of the map, all clients 
would be required to re-sync with Redis. To mitigate this, the grid's initial soft-dimensions
are large, as a cache reload is time-expensive.

The Occupancy grid is probabilistic, meaning each cell's occupancy is an integer in the range 
${[0..100]}$, with $0$ indicating certainly unoccupied, and $100$ indicating a certain occupation.

\subsection{Ray Tracing}

As the \textit{Khepera's} IR Range sensors give us the distance between the sensor and an object,
we can first transform this information from the robot's reference frame to the global (map)
reference frame, using a \textit{Transformation Matrix}:

\begin{equation}
  \begin{pmatrix}
    x_{map} \\
    y_{map}
  \end{pmatrix} = 
  \begin{pmatrix} 
    cos\Theta & sin\Theta \\
    -sin\Theta & cos\Theta
  \end{pmatrix}
  \cdot
  \begin{pmatrix}
    x_{robot} \\
    y_{robot}
  \end{pmatrix}
\end{equation}

Then using \textit{Bresenham's Line Algorithm}\cite{raytracealgo} we can raytrace between the
robot's position and the cell that we are seeing an object in; All the cells on this ray are 
updated -- If we've never seen before, they're marked as unoccupied, or if they are already 
marked in the map, the cell's value is updated to $0.7\times$ its value, given we now believe
it to be unoccupied. An occupancy grid of the task environment evolved by this process is shown 
in Figure \ref{fig:occupancygrid}.

\begin{figure}[h]
  \includegraphics[width=\textwidth]{../assets/early-occupancy-grid-rviz.png}
  \caption{
    \label{fig:occupancygrid}
    Occupancy grid, with overlaid pose (large red arrow) and Odometry Trail (smaller magenta arrows).
    Black indicates occupancy, white free space. Grey regions are not present in the Occupancy Grid.
  }
\end{figure}



%       ^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^


\section{Adaptive Monte-Carlo Localisation}\label{sec:amcl}

\begin{figure}[p]
  \begin{center}
    \includegraphics[width=0.7\textwidth]{../assets/plots/figure_1-3.png}
  \end{center}
  \caption{
    \label{fig:odometry_drift}
    Illustration of Odometry error. The robot was following the border of a simple square
    environment, but the trace of it's path shows a spiral instead. Axes are ${(x,y)}$
    coordinates in mm.
  }
\end{figure}

The existing system carried forward from \textit{Task 2}\cite{task2_report} maintained a pose estimate
that at each control loop epoch was updated by a discrete sensor model for the \textit{Khepera's} 
odometry. This model has no facility to model the compound error inherent to dead-reckoning with
odometry and as the robot continues to move in it's environment the belief about where the robot is quicky 
diverges from reality. As the task requires multiple excursions and returns to within 10cm of the nest,
this simple method alone is ineffective for localising the robot. THis inherent drift is illustrated by
Figure \ref{fig:odometry_drift}.

The \textit{Adaptive Monte-Carlo Localisation} Algorithm as outlined in 
\textit{Probabilistic Robotics}\cite{probabilisticrobot} provides a stochastic method of correcting
for compound error and localising on an Occupancy Grid:

\newpage
\textbf{\large Algorithm AMCL${(X_{t-1}, u_t, z_t)}$:}
\algsetup{indent=2em}
\begin{algorithmic}
  \STATE{$\bar{X_{t}}=X_{t}=\emptyset$}
  \FOR{$m=1$ \TO $M$}
  \STATE $x_{t}^{[m]}= \textrm{motion\_update}(u_{t},x_{(t-1)}^{[m]})$
  \STATE $w_{t}^{[m]}= \textrm{sensor\_update}(z_{t},x_{t}^{[m]})$
  \STATE $\bar{X_{t}}=\bar{X_{t}}+\langle x_{t}^{[m]},w_{t}^{[m]}\rangle $
  \ENDFOR
  \FOR{$m=1$ \TO $M$}
  \STATE $\textrm{draw } x_{t}^{[m]} \textrm{ from } \bar{X_{t}} \textrm{ with probability } \propto w_{t}^{[m]}$
  \STATE $X_{t}=X_{t}+x_{t}^{[m]}$
  \ENDFOR
  \RETURN $X_{t}$
\end{algorithmic}

Particles are drawn from the prior set ${X_{t-1}}$ of size $M$ using the \textit{Weighted Reservoir 
Sampling Algorithm}\cite{reservoirsample}, the effect of which is that particles with greater 
weight ${w_t^{[m]}}$ (i.e. the more probable hypotheses) have a greater chance of persisting once 
or multiple times in the new set of particles ${X_t}$. Note that the number of particles remains 
the same at all times.

TODO: How many particles we used

Figure \ref{fig:particle-disperse} illustrates how particles progressively diverge from the initial 
hypothesis, ${X_0}$. In our case, dynamical mapping affords a completely certain initial hypothesis
given the co-ordinate system is relative to said starting position; This prevents the need to
evenly distribute the particles over the environment at startup, so confidence in early localisations
is high with no multimodal properties.

\begin{figure}[p]
  \includegraphics[width=\textwidth]{../assets/particle-disperse-random.png}
  \caption{
    \label{fig:particle-disperse}
    Dispertion of Particles by Monte Carlo method, from left to right with increasing time and 
    a particularly high gain (i.e. each epoch disperses the particles greatly, assuming very large error)
  }
\end{figure}


%       ^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^

\newpage
\section{Planning}

Using SLAM, we can now proceed to the primary goal - gathering the maximum amount of food per unit time. For that we need to be able to plan out actions, which involves calculating routes to navigate the world and sequincing them accordingly.

\subsection{Path Planning Space}
\label{Path_Planning_Space}

\textit{(Path) Planning Space} is a term used  in this document to denote the representation of the physical world in one manner or another that allows the calculation of routes routes from one pose $(X,Y, \Theta)$ to another one. This is the basis on which calculations methods are chosen \textit{\S\ref{Path_Planning_Algorithm}Path Planning Algorithm}. 

\subsubsection{Method Chosen}

The main mehtods\cite{path_space} of planning are seen to be used on either of the following:

\begin{itemize}
	\item \textit{Occupancy Grid}
	\item \textit{Graph (Topological Map)}
\end{itemize}


The difference between these two from the perspective of planning is the efficiency of algorithm working on the data and the pre-processing of the data going to the algorithm. Because an occupancy grid is stored on a \textit{Redis-Server} and it has very fine definition, the number of grid squares (referred to as \textit{Grid Cerlls}) is immense. Therefore, to obtain a graph representation from that, every time a path replanning would have to take place, the conversion would have to take place on a very significant number of points. Therefore, the occupancy grid was chosen due to no conversion needing to be made on the data during runtime for planning, but rather a small alteration for the \textit{Path Planning Algorithm} which should not affect the alogirithm's performance.

\subsubsection{Alterations}

The granularity of the \textit{Planning Grid (Planning Space)} did not necessarily have to match that of the occupancy grid on Redis for the following reasons:


\begin{itemize}

	\item Robot Dimensions     - the robot's dimensions are larger than the mapping (server-side) granularity
	\item Odometry Distortion  - extremely finely planned path on an occupancy grid introduces many turns, increasing odometry drift rate considerably \cite{task2_report}
	\item Runtime Optimization - as long as there is a path to the goal and the robot can follow it, we wish to save as much processing time as we humanely can and plannign with bigger cell dimensions helps us save calculation time

\end{itemize}

Hence, it as decided that the rganularity would be available for configuring as a parameter before runtime without really limiting any way because that would diminish the further possible modifications to the aglorithm. However, by defaul it is set to be equal to the granularity of the occupancy grid.

Moreover, the \textit{(Grid) Cells} store their actual $(X ,Y)$ coordinates as well as occupancy - are they free space or not. Grid cells are stored in a two dimensional array which is indexed by using actual $(X ,Y)$ coordinates. Furthermore, said array is also dynamycally expanding in both dimensions so as to accomodate any number of cells (limited only by memory capacity) in order to not miss a valid optimal path due to any array bounds which also makes this solution more extensible and easily modifiable.

Therefore, formign a local cache of the Redis server data suitable for path search computations of virtually any kind. Lastly, because the occupancy data is stored on Redis, the implementation obtains unknown occupancies from the server and caches them locally in said two-dimensional array. 


%       ^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^


\subsection{Path Planning Algorithm}
\label{Path_Planning_Algorithm}

This method should allow the robot to navigate the mapped space between any two unoccupied \textit{(Grid) Cells} \textit{\S\ref{Code}} of the planning space (grid). 

\subsubsection{Research}

Firstly, there are many options for the \textit{Path Planning Algorithm} that search for a path between a goal and a destination location:

\begin{itemize}

	\item \textit{Floyd-Warshall Algorithm}\cite{path_warshall} - a many-to-many algorithm for planning routes
	\item \textit{Djikstra Algorithm}\cite{path_warshall} - a one-to-many algorithm
	\item \textit{A* Algorithm}\cite{path_astar}	- a one-to-one algorithm

\end{itemize}

These are some of the most common and robust pathing algorihtms used in pathing. However, even based on the iformation above it can be concluded that Floyd-Warshall algorithm is not waht we were lookign because w have a single strating point - the position of the robot. Moreover, empirical data\cite{path_efficiency} shows that the best-first search algorithm is considerably faster than the Djikstra algorithm and in fact is in general considered the fastest planning algorithm. Moreover, it's varioations as well as its purest form are used industry-wide in robotics. More reasons for choosing A* can be outlined in \textit{\S\ref{Path_Planning_Algorihtm_Alterations}}

\subsubsection{Method Chosen} 

Therefore, A* was chosen to be the algorithm of choice for path calculation to the target grid cell. The pseudocode explaining its basic operation is as follows:

\begin{figure}[H]
	  \centering 
	  \lstinputlisting[language=python]{../../astar_pseudo.py}\caption{The A* algorithm pseudocode\cite{path_astar_pseudocode} adapted to use the \textit{Planning Space} chosen - an occupancy grid }
\end{figure} 


\begin{figure}[H]
 	  \centering
          \lstinputlisting[language=python]{../../astar_path_reconstruction.py}\caption{The A* algorithm path reconstruction pseudocode\cite{path_astar_grid_no_grid} adapted to use the \textit{Planning Space} chosen - an occupancy grid }
\end{figure} 

\subsubsection{Alterations}
\label{Path_Planning_Algorihtm_Alterations}

The chosen \textit{Path Planning Algorihtm - A*} (\S\ref{Path_Planning_Algorithm}) uses the movement and \textit{Heuristic Cost} to estimate the total cost of  including cell into the claculated path. Therefore, as we know the pose of each grid cell, \textit{Euclidian Distances} were chosen to be a measure of (transition) cost between cells making it the cost function betwen any two cells $A$ and $B$. The \textit{Heuristic Function (Cost)} is $10$ times the Euclidian distance from currently considered cell to the goal. The reason for such a high number is that we wish to see the algorithm converge as fast as possible while findign an adequately short path to the desired destination whcih also reduces the amount of server requests for unknown occupancies. On a side note, the movement cost is simply the sum euclidian distances between nodes along the (considered) path involvind said cell.

Secondly, the A* pseudocode had to be adapted to work on a grid instead of a graph which was solved by a simple function obtaining its neighbours by using the considered cell's pose to get its adjacent ones from the \textit{\S\ref{Path_Planning_Space} Occupancy Grid}.

Secondly, most iterations of the A* algorithm rely on either graphs\cite{path_astar_grid_no_grid}  or only movements up, down, left or right\cite{path_astar_grid_no_diagonals}. However, it seemed like a wasted opportunity to not allow the robot to move diagonally. Such cells are referred to as  \textit{Diagonal Cells} - cells diagonal to the currently considered cell - whose adjacent cells we wish to consider for furhter pathing for the remainded of this report and in the code comments. Moreover, it had to be also accounter for scenarios where the diagonal cell is blocked by two of its neighbours and the diagonal cell can no longer participate in path calculation as shown in the following figure.


\begin{figure}[H]
	  \centering
	  \includegraphics[width=30em]{../assets/fig_astar_diagonal.jpg}
          \caption{The \textbf{left} figure shows the $central$ cell (square) is the so called \textit{Considered Cell} whose neighbours we are trying to obtain to plan a path. The \textbf{left} figure shows that we cannot consider the \textit{Diagonal Cell} $A$ as a valid neighbour because it is blocked by $B$ and $C$ making the movement along the red arrow as seen in the \textbf{right} figure impossible}
\end{figure} 






%       ^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^



\subsection{The Planner}

This section is concerned with the intergation of the algorithm and data structures described above into the main control loop and its interaction with previosuly established subsystems\cite{task2_report}. The algorithm determinign the next action or travel destination and sequencing said action is called the \textit{Planner} and is, therefore, responsible for maximizing the food collection rate by sequencing events governing said rate.

\subsubsection{Method Chosen}
\label{Planner_Principle}

Now that we are able to localize ourselves, knwo the map and can calculate paths on the grid, we can set priorites for action to maximize food gathering. Firstly, it is important to note that a it is considered that each \textit{Food Source} has only one unit of \textit{Food}. Upon return to the \textit{Nest} and droppign off currently collected food the robot resets the food sources which now have food units again, therefore, starting a new \textit{Food Collection Round (a.k.a. Round)}. Hence, the aciton priorites were set as follows

\begin{enumerate}
	\item \textit{Find} the first food source to begin periodic behavior in the following points
	\item \textit{Explore} once per Food Collection Round
	\item \textit{Collect} closest uncollected known / recorded food source
	\item \textit{Return} to the nest and drop off collected food
\end{enumerate}

Thus, we aim to find some food source first to start collecting food as soon as possible. After which exploration for new food sources becomes less of a priority and is only invoked once per round as we do not wish to waste too much time on exploration when we already have food to collect. Therefore, next on the list of priorities is collecting all the food before returning to the nest to drop it off because if we do not collect all the food before a new round start, it is reset - lost. After that is done, the robot returns to the nest and drops off collected food.


\begin{figure}[H]
	  \centering
	  \includegraphics[width=30em]{../assets/fig_planner.jpg}
          \caption{The planning algorithm - the \textit{Planner} in state-diagram form, this decision making tree is implored on overy iteration of the control loop and determines the action the system is to follow}
\end{figure} 

The robot aims to collect the closest food first (bases on Euclidian distances). The movement between cells is moevement along the vector between their recorded coordinates by adjusting the angle along the \textit{Vector of Approach}, same as \textit{Return Algorithm}\cite{task2_report}. Moreover, sometimes unxecpected events can happen that coud lead the robot away from said approach vector. Hence, the next destination is decided (as per above priority list) when the following events happen:

\begin{itemize}

	\item Food collected from a Food Source
	\item Food dropped off at nest - round finished
	\item Path lost - went a distance over the threshold away from the path

\end{itemize}

\subsubsection{Alterations}
\label{Planner_Algorithm_Alterations}

After reviewing initial \textit{\S\ref{Experimental_Results}Eperimenal Results} it was decided that due to the grid granularity being set (by default) in the same order of magnitude as robot dimensions, it is reasonable to assume that no two food sources can exist in the same grid cell as the cell sizes are assumed to be set by the user / programmer to a granularity not exceeding robot dimensions. Lastly, because the algorithm needs to find new food sources, the boredom mechanism \cite{task1_report} was reinstated into the control loop and is the exploration mechanism and is utilized during the \textit{Find} stages of the algorithm. 

Moreover, it also motivated the introduction of a \textit{Spiral} mechanism which makes the robot spiral away from the expected location of the food source. The is that when the robott first find a food source, there is no odometry\textit{Task 2}\cite{task2_report} or other localization error and therefore know we are physically at the correct location to collect food (at the food source). However, due to error accumulation as noted above, the next time the robot thinks it is at the food source, physically it might not be. That is when it begins spiralling and the operator indicates \textit{\S\ref{Planner_User_Input}}  when the food source is actually reached. This ensures that even in the presence of errors we do not miss food. This, however, should not be an issue unless localization has massive errors and further improvements of the system might eliminate the need for spiralling. 

%       ^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^


\subsection{User Input and Alterations}
\label{Planner_User_Input}

The user input indicates important information related to food collection. In particular pressing keys has the following effect

\begin{itemize}
	\item \textit{Space} - indicates that the robot has found a new food source
	\item \textit{Enter} - indicates that have sucessfully revisited a previosly recorded food source (stopping the \textit{Spiral})

\end{itemize}

The reason for havign two separate keys like taht is due to the differentiation between we first visiting a food source and attempting to re-visit the food source. Therefore to allowing distinguishing when to record a new food source and gather food immediately, or start a spiral\textit{\S\ref{Planner_Algorithm_Alterations}}. 


\subsection{Subsystem Interaction}

Lastly, the integration of the algorithm into the main system is seamless and practically mimics the integration of the \textit{Return Algorithm}\cite{task2_report} a.k.a. the \textit{Bug 2.4.1.1.2}. The difference is now we know where there are walls or free space. hence, the robot can fully relay the control to the planner, unless we are exploring using "boredom"\cite{task2_report} or are being "unstuck"\cite{task2_report} without fear of the robot crashing into the wall. 

Therefore, ensuring that SLAM and A* are the main control element in the system, unless we need to avoid collision. A further note is that the above distinction is not as clear in the \textit{\S\ref{Code} Code} because of the location of methods, however, the end result (and aim) is as descibed above.


\section{Experimental Result}
\label{Experimental_Results}


%       ^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^v^





TODO make sure angus has a pic of waht an occupancy grid is
TODO comment somehow on the ganularity effect on performance (and do tests)
TODO make sure occupancy grid is already described in a previous section
TODO reference pictures
TODO set granularity to robot dimension
TODO insert stuff from google drive
TODO: Empirical results


TODO Rule the world



\begin{thebibliography}{}

\bibitem{task1_report} 
\par{IAR 2016 Task1 Report}
\\
\textit{Angus Pearson, Jevgenij Zubovskij}

\bibitem{task2_report} 
\par{IAR 2016 Task2 Report}
\\
\textit{Angus Pearson, Jevgenij Zubovskij}


\bibitem{principlesrobot} % The bug one
\par{Principles of Robot Motion: Theory, Algorithms, and Implementation \S2.1 `Bug Algorithms'}
\\
\textit{Howie Choset}


\bibitem{probabilisticrobot} % The AMCL one
\par{Probabilistic Robotics (Intelligent Robotics and Autonomous Agents), MIT Press, 2005}
\\
\textit{Thrun, Sebastian and Burgard, Wolfram and Fox, Dieter}


\bibitem{reservoirsample}
\par{Reservoir Sampling, Dictionary of Algorithms and Data Structures}
\\
\textit{Black, Paul E. (26 January 2015)}


\bibitem{raytracealgo}
\par{A Linear Algorithm for Incremental Digital Display of Circular Arcs}
\\
\textit{Commun. ACM, J Bresenham, Feb. 1977}

\bibitem{path_space}
\par{Map Representation Comparison and Planning (online article)}
\\
\textit{http://correll.cs.colorado.edu/?p=965}



\bibitem{path_warshall} 
\par{Theory of Algorithms (lecture)}
\\
\textit{http://cs.winona.edu/lin/cs440/ch08-2.pdf}

\bibitem{path_djikstra} 
\par{Greedy Algorithms (online article)}
\\
\textit{http://www.geeksforgeeks.org/greedy-algorithms-set-6-dijkstras-shortest-path-algorithm/}

\bibitem{path_astar}
\par{A* Comparison (online article)}
\\
\textit{http://theory.stanford.edu/~amitp/GameProgramming/AStarComparison.html}

\bibitem{path_efficiency} 
\par{Comparative Study of Path Planning Algorithms}
\\
\textit{http://research.ijcaonline.org/volume39/number5/pxc3877058.pdf}

\bibitem{path_astar_pseudocode} 
\par{A* Search Algorithm (online article)}
\\
\textit{http://web.mit.edu/eranki/www/tutorials/search/}



\bibitem{path_astar_grid_no_diagonals} 
\par{Introduction to A* (online article)}
\\
\textit{http://theory.stanford.edu/~amitp/GameProgramming/AStarComparison.html}



\bibitem{path_astar_grid_no_grid} 
\par{A* Search Alogorith (online article)}
\\
\textit{https://en.wikipedia.org/wiki/A*\_search\_algorithm}




\end{thebibliography}

\newpage
\section*{Appendix}
\subsection{Code Listings}
\label{Code}
\lstinputlisting[language=python]{../../main.py}
\lstinputlisting[language=python]{../../data.py}
\lstinputlisting[language=python]{../../comms.py}
\lstinputlisting[language=python]{../../mapping.py}
\lstinputlisting[language=python]{../../state.py}
\lstinputlisting[language=python]{../../utils.py}
\lstinputlisting[language=python]{../../pathing_state.py}
\lstinputlisting[language=python]{../../pathing_algorithm.py}
\lstinputlisting[language=python]{../../astar.py}
\lstinputlisting[language=python]{../../navigation_state.py}
\lstinputlisting[language=python]{../../navigation_algorithm.py}
\lstinputlisting[language=python]{../../odometry_algorithm.py}
\lstinputlisting[language=python]{../../odometry_state.py}
\lstinputlisting[language=python]{../../constants.py}
\lstinputlisting{../../requirements.txt}
\lstinputlisting{../../redis-min.conf}



\end{document}
